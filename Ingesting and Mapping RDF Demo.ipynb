{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import necessary modules\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import rdflib\n",
    "import arcpy\n",
    "import glob\n",
    "import requests\n",
    "import visJS2jupyter.visJS_module\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from rdflib import Graph\n",
    "from gastrodon import LocalEndpoint, one, QName\n",
    "from arcgis.gis import GIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Variables\n",
    "\n",
    "#sourcePath = r'C:\\Users\\jame9353\\Box Sync\\Data\\NetOwl\\esri_all_out2'\n",
    "docsPath = r'C:\\Users\\jame9353\\Documents\\GitHub\\RDFtoNeo4J\\Atmospherics'\n",
    "rdfOutDir = r'C:\\Data\\RDF'\n",
    "rdfOutExt = \".rdf\"\n",
    "fileOutDir = r'C:\\Users\\jame9353\\Documents\\GitHub\\RDFtoNeo4J\\Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Walks through the docsPath, identifying files, and appends them to a list.\n",
    "docs = []\n",
    "for root, dirs, files in os.walk(docsPath):\n",
    "    for f in files:\n",
    "        filePath = os.path.join(root, f)\n",
    "        docs.append(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Defines a function that will pass documents derived from the list\n",
    "# above to the NetOwl API.  \n",
    "#Function checks the type of document and makes necessary adjustment \n",
    "# to the POST command.\n",
    "#Function has three inputs:\n",
    "#    1.  inFile:  This is the file that will be passed to the NetOwl API\n",
    "#    2.  outPath: Path where the output file will be saved\n",
    "#    3.  outExtension:  the file type that will be saved (RDF, etc..)\n",
    "\n",
    "def netowlCurl(inFile, outPath, outExtension):\n",
    "    headers = {\n",
    "    'accept': 'application/rdf+xml',\n",
    "    'Authorization': 'netowl ff5e6185-5d63-459b-9765-4ebb905affc8',\n",
    "    }\n",
    "    \n",
    "    if inFile.endswith(\".txt\"):\n",
    "        headers['Content-Type'] = 'application/msword'\n",
    "        print(\"Document is a text file...\")\n",
    "    elif inFile.endswith(\".pdf\"):\n",
    "        headers['Content-Type'] = 'application/pdf'\n",
    "        print(\"Document is a PDF...\")\n",
    "    elif inFile.endswith(\".docx\"):\n",
    "        headers['Content-Type'] = 'application/msword'\n",
    "        print(\"Document is a Word Document...\")\n",
    "    \n",
    "    params = (\n",
    "        ('language', 'english'),\n",
    "    )\n",
    "    \n",
    "    data = open(inFile, 'rb').read()\n",
    "    response = requests.post('https://api.netowl.com/api/v2/_process', headers=headers, params=params, data=data, verify=False)\n",
    "    r = response.text\n",
    "    outPath = outPath\n",
    "    fileName = os.path.split(d)[1]\n",
    "    if os.path.exists(outPath) == False:\n",
    "        os.mkdir(outPath, mode=0o777,)\n",
    "    outFile = os.path.join(outPath, fileName + outExtension)\n",
    "    #print(len(r))\n",
    "    #print(outFile)\n",
    "    open(outFile, \"w\", encoding=\"utf-8\").write(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Iterates though the docs list created previously and \n",
    "# runs the function for each of the documents found. \n",
    "#Passes the function a document derived from the list,\n",
    "# and two variables created in a previous step. \n",
    "\n",
    "for d in docs:\n",
    "    netowlCurl(d, rdfOutDir, rdfOutExt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates a Graph Object that will store all the result of a parse operation \n",
    "# in the next step. \n",
    "g = Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Walks through output path from the netowlCurl function and parses all RDF/XML Documents\n",
    "for root, dir, files in os.walk(rdfOutDir):\n",
    "    for file in files:\n",
    "        if file.endswith('.rdf'):\n",
    "            filePath = os.path.join(root, file)\n",
    "            print(\"Parsing \" + file + \"...\")\n",
    "            try:\n",
    "                g.parse(filePath, format='xml')\n",
    "            except Exception as ex:\n",
    "                print(ex) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create Local SPARQL Endpoint on graph created in previous step\n",
    "e = LocalEndpoint(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Uses the SPARQL endpoint to query all of the relationship types and returns the top 10\n",
    "properties=e.select(\"\"\"\n",
    "   SELECT ?p (COUNT(*) AS ?cnt) {\n",
    "      ?s ?p ?o .\n",
    "   } GROUP BY ?p ORDER BY DESC(?cnt)\n",
    "\"\"\")\n",
    "properties.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Graphs the top 10 relationship types\n",
    "with plt.xkcd():\n",
    "    properties.head(10)[\"cnt\"].plot.pie(figsize=(6,6)).set_ylabel('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Writes the full relationship types data frame to a CSV document\n",
    "file_name = os.path.join(fileOutDir, 'predicates.csv') \n",
    "properties.to_csv(file_name, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SPARQL query to identify various entity types inside of the graph\n",
    "pd.set_option(\"display.width\",150)\n",
    "pd.set_option(\"display.max_colwidth\",150)\n",
    "sparql=e.select(\"\"\"\n",
    "   SELECT ?s ?o ?label{\n",
    "      ?s netowl:Entity.Person..name ?o .\n",
    "      ?s rdfs:label ?label .\n",
    "    }\n",
    "\"\"\")\n",
    "sparql.set_index(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Queries the SPARQL endpoint for the various addresses located in the documents\n",
    "address=e.select(\"\"\"\n",
    "   SELECT ?s ?o ?label{\n",
    "      ?s netowl:Entity.Address.Mail..name ?o .\n",
    "      ?s rdfs:label ?label .\n",
    "    }\n",
    "\"\"\")\n",
    "address.set_index(\"label\")\n",
    "#address_file = r'C:\\Users\\jame9353\\Documents\\GitHub\\RDFtoNeo4J\\Data\\addresses.csv'\n",
    "#address.to_csv(address_file, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Makes a connection to ArcGIS Online and adds a map widget centered over Baltimore, MD\n",
    "gis = GIS(\"https://esrifederal.maps.arcgis.com\", client_id = \"Sama2eyhY8UFPwQb\")\n",
    "map = gis.map(\"Baltimore\")\n",
    "map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Geocodes the addresses and adds them to the map widget as a feature collection\n",
    "locations = gis.content.import_data(address, {\"Address\" : \"o\"})\n",
    "map.add_layer(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates a hosted feature service from the feature \n",
    "# collection created in the previous step\n",
    "loc_properties = {\n",
    "    \"title\":\"NetOwl_Addresses\",\n",
    "    \"text\": json.dumps({\"featureCollection\": {\"layers\": [dict(locations.layer)]}}),\n",
    "    \"type\":\"Feature Collection\"}\n",
    "loc = gis.content.add(loc_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Queries for the MGRS coordinates and writes them to a CSV file\n",
    "mgrs=e.select(\"\"\"\n",
    "   SELECT ?s ?o ?label{\n",
    "      ?s netowl:Entity.Numeric.Coordinate.Mgrs..name ?o .\n",
    "      ?s rdfs:label ?label .\n",
    "    }\n",
    "\"\"\")\n",
    "mgrs.set_index(\"o\")\n",
    "mgrs_file = os.path.join(fileOutDir,'mgrs_coords.csv')\n",
    "mgrs.to_csv(mgrs_file, sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converts coordinates located in the MGRS CSV into Lat/Longs, turns this into a shapefile\n",
    "outShpDir = os.path.join(fileOutDir, 'OutShp')\n",
    "if os.path.exists(outShpDir) == False:\n",
    "    os.mkdir(outShpDir, mode=0o777,)\n",
    "arcpy.ConvertCoordinateNotation_management(in_table=mgrs_file, out_featureclass=os.path.join(outShpDir,\"NetOwl_MGRS.shp\"), x_field=\"o\", y_field=\"o\", input_coordinate_format=\"MGRS\", output_coordinate_format=\"DD_NUMERIC\", id_field=\"\", spatial_reference=\"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119522E-09;0.001;0.001;IsHighPrecision\", in_coor_system=\"GEOGCS['GCS_WGS_1984',DATUM['D_WGS_1984',SPHEROID['WGS_1984',6378137.0,298.257223563]],PRIMEM['Greenwich',0.0],UNIT['Degree',0.0174532925199433]]\", exclude_invalid_records=\"INCLUDE_INVALID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Zips up the shapefile created in the previous step\n",
    "\n",
    "outZip = fileOutDir\n",
    "\n",
    "def zipShapefilesInDir(inDir, outDir):\n",
    "    if not os.path.exists(inDir):\n",
    "        arcpy.AddMessage(\"Input directory %s does not exist!\" % inDir)\n",
    "        return False\n",
    "\n",
    "    if not os.path.exists(outDir):\n",
    "        arcpy.AddMessage(\"Creating output directory %s\" % outDir)\n",
    "        os.mkdir(outDir)\n",
    "\n",
    "    arcpy.AddMessage(\"Zipping shapefile(s) in folder %s to output folder %s\" % (inDir, outDir))\n",
    "\n",
    "    for inShp in glob.glob(os.path.join(inDir, \"*.shp\")):\n",
    "        global outZip\n",
    "        outZip = os.path.join(outDir, os.path.splitext(os.path.basename(inShp))[0] + \".zip\")\n",
    "\n",
    "        zipShapefile(inShp, outZip)\n",
    "    return True\n",
    "\n",
    "\n",
    "def zipShapefile(inShapefile, newZipFN):\n",
    "    arcpy.AddMessage('Starting to Zip ' + (inShapefile) + ' to ' + (newZipFN))\n",
    "\n",
    "    if not (os.path.exists(inShapefile)):\n",
    "        arcpy.AddMessage(inShapefile + ' Does Not Exist')\n",
    "        return False\n",
    "\n",
    "    if (os.path.exists(newZipFN)):\n",
    "        arcpy.AddMessage('Deleting ' + newZipFN)\n",
    "        os.remove(newZipFN)\n",
    "\n",
    "    if (os.path.exists(newZipFN)):\n",
    "        arcpy.AddMessage('Unable to Delete' + newZipFN)\n",
    "        return False\n",
    "\n",
    "    zipobj = zipfile.ZipFile(newZipFN, 'w')\n",
    "\n",
    "    for infile in glob.glob(inShapefile.lower().replace(\".shp\", \".*\")):\n",
    "        if os.path.splitext(infile)[1].lower() != \".zip\":\n",
    "            arcpy.AddMessage(\"Zipping %s\" % (infile))\n",
    "            zipobj.write(infile, os.path.basename(infile), zipfile.ZIP_DEFLATED)\n",
    "\n",
    "    zipobj.close()\n",
    "    return True\n",
    "\n",
    "zipShapefilesInDir(outShpDir, fileOutDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Uploads the shapefile to ArcGIS Online and publishes it as a feature service\n",
    "tempItem = gis.content.add({\"title\":\"NetOwl_MGRS\", \"type\":\"Shapefile\"}, outZip)\n",
    "mgrsLyr = tempItem.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adds a map widget centered over Iraq\n",
    "map1 = gis.map()\n",
    "map1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Searches for the feature service created from the MGRS Coordinates and adds it to the map widget\n",
    "mgrsData = gis.content.search(\"NetOwl_MGRS\", item_type=\"feature service\")[0]\n",
    "mgrsData\n",
    "map1.add_layer(mgrsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Queries for the Lat/Long coordinates located in the document\n",
    "latlong=e.select(\"\"\"\n",
    "   SELECT ?s ?o ?label{\n",
    "      ?s netowl:Entity.Numeric.Coordinate.Latlong..name ?o .\n",
    "      ?s rdfs:label ?label .\n",
    "    }\n",
    "\"\"\")\n",
    "latlong.set_index(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Queries for the Lat/Long coordinates located in the document\n",
    "city=e.select(\"\"\"\n",
    "   SELECT ?s ?o ?label{\n",
    "      ?s netowl:Entity.Place.City..name ?o .\n",
    "      ?s rdfs:label ?label .\n",
    "    }\n",
    "\"\"\")\n",
    "city.set_index(\"o\")\n",
    "\n",
    "city = gis.content.import_data(city, {\"City\" : \"o\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map2 = gis.map()\n",
    "map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map2.add_layer(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city_properties = {\n",
    "    \"title\":\"NetOwl_Cities\",\n",
    "    \"text\": json.dumps({\"featureCollection\": {\"layers\": [dict(city.layer)]}}),\n",
    "    \"type\":\"Feature Collection\"}\n",
    "loc = gis.content.add(city_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Creates a NetworkX Graph for visualization\n",
    "nxG = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Queries the SPARQL endpoint and generates a list of the edges to be used in the Graph\n",
    "edgeGraph=e.select(\"\"\"\n",
    "   SELECT ?labelO ?labelS{\n",
    "      ?s ?p ?o .\n",
    "      ?o rdfs:label ?labelO .\n",
    "      ?s rdfs:label ?labelS .\n",
    "    }\n",
    "\"\"\")\n",
    "edgeGraph.set_index(\"labelS\")\n",
    "\n",
    "#Adds edges to NetworkX Graph\n",
    "for i, elrow in edgeGraph.iterrows():\n",
    "    nxG.add_edge(elrow[0], elrow[1], attr_dict=elrow[1:].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nodes = list(nxG.nodes()) # must cast to list to maintain compatibility between nx 1.11 and 2.0\n",
    "edges = list(nxG.edges()) \n",
    "\n",
    "pos = nx.spring_layout(nxG)\n",
    "nodes_dict = [{\"id\":n,\n",
    "              \"x\":pos[n][0]*1000,\n",
    "              \"y\":pos[n][1]*1000} for n in nodes]\n",
    "\n",
    "node_map = dict(zip(nodes,range(len(nodes))))\n",
    "\n",
    "edges_dict = [{\"source\":node_map[edges[i][0]], \"target\":node_map[edges[i][1]], \n",
    "              \"title\":'test'} for i in range(len(edges))]\n",
    "\n",
    "visJS2jupyter.visJS_module.visjs_network(nodes_dict,edges_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
